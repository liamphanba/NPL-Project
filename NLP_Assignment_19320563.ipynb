{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4638a871a58694a77473a590728ebf25047cd6eb"
   },
   "source": [
    "# NLP Assignment: Generating Trump Tweets with N-Gram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4f13ed7359c87e397229104c1bcf18eb20603ad"
   },
   "source": [
    "In this assignment, you will use n-gram language models (LM) to model tweets (social media statements) from or about the former U.S. president Donald Trump. The goal will then be to generate new tweets, or do autocompletion, in the writing style of Trump's tweets. The tweets have been scraped from the Twitter social media (since then renamed \"X\").\n",
    "\n",
    "Before starting this assignment, the appended `NLP_ngram_cheatsheet.ipynb` notebook provides a tutorial on n-grams and LM basics, using the `nltk` package.\n",
    "\n",
    "Please code the necessary steps in python, and provide answers in Markdown format in this notebook, under the corresponding instructions and questions below.\n",
    "\n",
    "Please rename your final file `NLP_Assignment_STUDENTID.ipynb` for submission on moodle, and make sure you \"run all\" with a fresh kernel, so that outputs show correctly and in order in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STUDENT ID:** 19-320-563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('popular', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Import, inspect and preprocess the text data\n",
    "\n",
    "- Import the provided dataset, `Trump_tweets.csv`. We are interested in the variable `Tweet_Text`, which gives the content of each tweet. \n",
    "- Before tokenizing, start by cleaning the tweets' format. You should at least normalize the different types of apostrophes and quotes (e.g. `` ’, ”, ` ``) to the corresponding ` ' ` or ` \" `, remove line breaks `\\n` (careful about not \"merging\" words), and remove multiple spacing. Also make sure urls (e.g. `https://t.co/wPk7QWpK8Z`) are not split into too many meaningless tokens. \n",
    "- (Facultative) Feel free to perform additional cleaning steps that you believe will improve the tokenization or the downstream LMs (in which case, briefly explain why).\n",
    "- Tokenize the `Tweet_Text` corpus into a list of tokenized tweets (documents). The result should be a list of lists containing word-level tokens (e.g. words, punctuation, and other \"special words\").\n",
    "- Show the result for the first five tweets of the corpus.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32c5ad89e3e61b143e940d50a0d0ee602dadfe3f"
   },
   "source": [
    "## Part 2: Fitting and Accessing a Trump Tweet LM\n",
    "\n",
    "### Ex. 2.1: LM fitting function\n",
    "Create a function that takes as arguments (at least) the desired order $n$ of the model and a tokenized training corpus, and that returns the \"simple\" Maximum Likelihood Estimator (MLE) language model, fitted on the given training corpus.  \n",
    "Then, use your function to fit a MLE language model of order $n=3$ to the Trump Tweets corpus.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 2.2: Vocabulary\n",
    "- How many distinct tokens are in the model's vocabulary? Is that the same number of distinct tokens that appear in the tokenized corpus?\n",
    "- Lookup the tokens of the sentence `\"I love UNIGE students!\"` in the model's vocabulary. Explain what you observe, and why. \n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af5a0851a2f8707ea2e172681342ed3ecd872328"
   },
   "source": [
    "### Ex. 2.3: Token probabilities\n",
    "- When it comes to ngram models the training boils down to counting the ngrams from the training corpus. Using your fitted model, how many times do the following appear in the training data: ``'America', 'Trump', 'I will', 'will never forget'``.\n",
    "- Then, compute the following word occurrence probabilities ('scores') in the Trump Tweets corpus, and briefly explain what the returned numbers mean about the training data:\n",
    "    - $\\mathbb{P}($'America'$)$,\n",
    "    - $\\mathbb{P}($'Trump'$)$,\n",
    "    - $\\mathbb{P}($'will'$\\vert $'I'$)$,\n",
    "    - $\\mathbb{P}($'forget'$\\vert $'will never'$)$.\n",
    "- Briefly explain, with a formula, how those probabilities are obtained from the n-gram counts.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18f9e0a8d0aba302532b8a84f342d1bf4d3e202a"
   },
   "source": [
    "## Part 3: Generation using N-gram Language Model\n",
    "\n",
    "### Ex. 3.1: Tweet generator\n",
    "Create a python function to generate new Trump Tweets. It should:\n",
    "- take as input arguments: a fitted `nltk.lm.model`, a maximum number of words (integer), a text seed (initial context tokens), and a random \"RNG\" seed for generation,\n",
    "- output a newly generated Trump Tweet, according to the input arguments, post-processed as a single text string that is formatted like a tweet.\n",
    "\n",
    "*Hints:* `nltk.tokenize.treebank.TreebankWordDetokenizer()` and its `.detokenize()` method can help with post-processing. Pay attention to show things like `@user` mentions, urls, punctuation, etc... in a \"correct\" format.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3.2: Initial context\n",
    "To generate a full tweet from a LM of order $n$, explain what should be the text seed (i.e. the initial context tokens). Set the default value for the relevant argument of your function in 3.1 accordingly.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 3.3: Generate tweets\n",
    "Generate a few new tweets using your new function and the LM fitted in Part 2. For reproducibility, use a random RNG seed to show them. \n",
    "\n",
    "*Facultative:* show a few examples that you find interesting, representative or funny.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Smoothing and model comparison\n",
    "\n",
    "### Ex. 4.1: Smoothed LM alternatives to simple MLE\n",
    "Modify the function that you defined in 2.1 by adding an argument that allows changing the `nltk.lm` language model that is fitted in the function (e.g. to fit a Laplace or a Lidstone model instead of the simple MLE). \n",
    "Also briefly explain what is the difference between Laplace, Lidstone and the simple MLE language models.\n",
    "\n",
    "*Hint:* Your function might need more than a single additional argument, if some LM have hyperparameters.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 4.2: Qualitative model comparison \n",
    "With $n=1,2,3,4$, fit and generate new tweets from the simple MLE and from the Laplace LM of orders $n$. \n",
    "- Compare the results between the different $n$ values and between the two models. \n",
    "- What are the main differences for generation? Which model(s) do you think might be the best options for generating new realistic tweets?\n",
    "- Do you see hints of those differences in the generated tweets?\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 4.3: Quantitative evaluation and comparison\n",
    "- Split the tokenized Trump Tweets corpus into a (reproducible) training set (80%) and a test set (20%). \n",
    "- Compute the train and test 3-gram perplexity scores of a simple MLE LM, a Laplace LM, and a Lidstone LM with $\\gamma=0.1$. Use model order $n=3$ for each.\n",
    "- Compare and discuss the obtained train and test perplexity scores of the three models. Argue which model might represent the Trump Tweets data best.\n",
    "\n",
    "*Hint:* To compute the perplexity correctly, you might need to preprocess the relevant corpus documents to a list of padded $n$-grams.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex. 4.4: Hyper-parameter tuning\n",
    "- Perform a grid-search to select the best hyperparameter values for $n$ and $\\gamma$, for the Lidstone LM. You want to select the model that generalizes best to new data.\n",
    "- What do you observe in the obtained perplexity scores? Was it expected? Explain it in statistical terms.\n",
    "\n",
    "*Hint:* Maybe try a few values for $n$ and $\\gamma$ by hand to identify the general hyperparameter region of interest before defining a more thorough hyperparameter value grid.\n",
    "\n",
    "##### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
